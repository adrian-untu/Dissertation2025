\chapter{Methodology}

This chapter outlines the methodological framework adopted in this study. The research leverages natural language processing (NLP), structured rule-checking, and the Moral Machine dataset to evaluate the ethical integrity of autonomous vehicle decision scenarios. The following sections detail the dataset processing, scenario reconstruction, ethical rule design, and evaluation approach.

\section{Overview of the System Architecture}

The proposed system consists of five main components:

\begin{enumerate}
    \item \textbf{Data Acquisition and Unzipping}: Extracting scenario files from compressed datasets.
    \item \textbf{Scenario Reconstruction}: Converting tabular or structured input into natural language descriptions.
    \item \textbf{NLP Analysis}: Using spaCy to lemmatize and extract scenario intent and features.
    \item \textbf{SAE Level Detection}: Determining the appropriate automation level based on detected keywords.
    \item \textbf{Ethics Rule Matching}: Comparing inferred context with ethical rules from a structured SQLite database.
\end{enumerate}

Each step is designed to incrementally transform the raw data into an interpretable format that can be ethically analyzed.

\section{Data Sources}

\subsection{The Moral Machine Dataset}

The core dataset comes from the Moral Machine project \cite{awad2018moral}, which includes scenarios involving autonomous vehicles choosing between groups of pedestrians or passengers. Files are provided in both CSV and pickle format, some containing human-labeled scenario types, decision actions, and character counts.

\subsection{Scenario Structure}

Each scenario includes:
\begin{itemize}
    \item Number and type of individuals on each side
    \item Whether the AV must intervene
    \item Whether the individuals are in or outside the vehicle
    \item Scenario theme (e.g., gender, lawfulness, profession)
\end{itemize}

\section{Scenario Text Generation}

\subsection{Natural Language Representation}

Structured rows are converted into readable scenario descriptions using Python functions such as \texttt{row\_to\_scenario\_text()} and \texttt{row\_to\_scenario\_text\_gpt()}:

\begin{quote}
``The vehicle is in the car. On side 1, there are: 2x woman, 1x doctor. On side 2, there are: 1x dog, 1x elderly man. This vehicle is fully autonomous. The vehicle must decide whether to intervene.''
\end{quote}

These representations are intentionally phrased to trigger relevant ethical and automation-level keywords during analysis.

\section{NLP and SAE Level Inference}

\subsection{Text Preprocessing}

The spaCy library is used for:
\begin{itemize}
    \item Lowercasing and tokenization
    \item Lemmatization
    \item Filtering stop words and non-alphabetic tokens
\end{itemize}

\subsection{Keyword Matching}

Each SAE level (0--5) is mapped to a keyword set (e.g., ``manual control'', ``self-driving'', ``autonomous''). A regular expression match scans for these patterns. The first match assigns the inferred level to the scenario.

\section{Ethical Rule Database}

\subsection{Database Construction}

An SQLite database is created with the schema:

\begin{quote}
\texttt{(id INTEGER, sae\_level INTEGER, principle TEXT, rule\_description TEXT)}
\end{quote}

Each SAE level contains multiple ethical principles, such as:

\begin{itemize}
    \item \textbf{SAE Level 2:} ``Transparency'' – ``System must communicate its operational limits and intention to the driver.''
    \item \textbf{SAE Level 5:} ``Non-Discrimination'' – ``Decisions must not prioritize safety based on race, age, or economic status.''
\end{itemize}

\subsection{Rule Matching}

Once a scenario's SAE level is inferred, a matching rule is selected from the database. The system checks whether any keywords from the ethical guideline appear in the scenario. If not, the system flags a potential ethical conflict.

\section{Evaluation Procedure}

\subsection{Validation Function}

The function \texttt{validate\_decision(row)} checks whether a given scenario text passes the ethics check. If the scenario contradicts the expected rule (e.g., violates ``non-discrimination''), it is marked as ethically invalid.

\subsection{Interpretation and Reporting}

All results are summarized in terms of:
\begin{itemize}
    \item Total number of evaluated scenarios
    \item Number of conflicts detected
    \item Proportion of ethically aligned decisions
\end{itemize}

This forms the basis for quantitative reporting in Chapter 5.

\section{Tools and Libraries}

\begin{itemize}
    \item \textbf{Python 3.10+}
    \item \textbf{spaCy} for NLP processing
    \item \textbf{Pandas} for data wrangling
    \item \textbf{SQLite3} for rule storage
    \item \textbf{re (regex)} for keyword detection
\end{itemize}

\section{Summary}

This chapter described the pipeline from scenario loading to ethical rule matching. The methodology emphasizes transparency, modular design, and linguistic interpretability. The next chapter presents the results of applying this methodology to hundreds of Moral Machine scenarios.

